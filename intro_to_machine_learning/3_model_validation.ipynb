{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Measuring model quality is the key to iteratively improving your models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Model Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll want to evaluate almost every model you ever build. In most (though not all) applications, the relevant measure of model quality is *predictive accuracy*. In other words, will the model's predictions be close to what actually happens?\n",
    "\n",
    "There are many metrics for summarizing model quality, but we'll start with **Mean Absolute Error (also called MAE)**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mean Absolute Error**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prediction error for each house is:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'error=actualâˆ’predicted' \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, if a house cost \\\\$150,000 and you predicted it would cost \\\\$100,000 the error is \\\\$50,000.\n",
    "\n",
    "With the **MAE** metric, we take the absolute value of each error. This converts each error to a positive number. We then take the average of those absolute errors. This is our measure of model quality. In plain English, it can be said as\n",
    "\n",
    "On average, our predictions are off by about X."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a model to calculate its MAE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "melbourne_file_path = 'C:/Users/AndresCervantesNassa/Documents/GitHub/kaggle-courses/intro_to_machine_learning/data/melb_data.csv'\n",
    "melbourne_data = pd.read_csv(melbourne_file_path) \n",
    "filtered_melbourne_data = melbourne_data.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "melbourne_features = ['Rooms', 'Bathroom', 'Landsize', 'BuildingArea', 'YearBuilt', 'Lattitude', 'Longtitude']\n",
    "X = filtered_melbourne_data[melbourne_features]\n",
    "\n",
    "y = filtered_melbourne_data.Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "434.71594577146544"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Define model\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "melbourne_model = DecisionTreeRegressor(random_state=1)\n",
    "\n",
    "# 2. Fit model\n",
    "melbourne_model.fit(X, y)\n",
    "\n",
    "# 3. Predict model\n",
    "predicted_home_prices = melbourne_model.predict(X)\n",
    "\n",
    "# 4. Evaluate model\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "mean_absolute_error(y, predicted_home_prices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Problem with \"In-Sample\" Scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We used a single \"sample\" of houses for both building the model and evaluating it**. Here's why this is bad.\n",
    "\n",
    "Imagine that, in the large real estate market, door color is unrelated to home price.\n",
    "\n",
    "However, in the sample of data you used to build the model, all homes with green doors were very expensive. The model's job is to find patterns that predict home prices, so it will see this pattern, and it will always predict high prices for homes with green doors.\n",
    "\n",
    "Since this pattern was derived from the training data, the model will appear accurate in the training data.\n",
    "\n",
    "But if this pattern doesn't hold when the model sees new data, the model would be very inaccurate when used in practice.\n",
    "\n",
    "Since models' practical value come from making predictions on new data, **we measure performance on data that wasn't used to build the model. The most straightforward way to do this is to exclude some data from the model-building process**, and then use those to test the model's accuracy on data it hasn't seen before. This data is called validation data.\n",
    "\n",
    "The scikit-learn library has a function 'train_test_split' to break up the data into two pieces. We'll use some of that data as training data to fit the model, and we'll use the other data as validation data to calculate mean_absolute_error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "263612.540348612\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_X, val_X, train_y, val_y = train_test_split(X, y, random_state = 0)\n",
    "\n",
    "# 1/4 Define\n",
    "melbourne_model = DecisionTreeRegressor()\n",
    "\n",
    "# 2/4 Fit\n",
    "melbourne_model.fit(train_X, train_y)\n",
    "\n",
    "# 3/4 Predict\n",
    "val_predictions = melbourne_model.predict(val_X)\n",
    "print(mean_absolute_error(val_y, val_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MAE increased from \\\\$434 to \\\\$250,000! The error in new data is about a quarter of the average home value!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data split into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First in-sample predictions: [208500. 181500. 223500. 140000. 250000.]\n",
      "Actual target values for those homes: [208500, 181500, 223500, 140000, 250000]\n"
     ]
    }
   ],
   "source": [
    "# Previous model\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Path of the file to read\n",
    "iowa_file_path = 'C:/Users/AndresCervantesNassa/Documents/GitHub/kaggle-courses/intro_to_machine_learning/data/home_data_for_ml_course.csv'\n",
    "home_data = pd.read_csv(iowa_file_path)\n",
    "\n",
    "y = home_data.SalePrice\n",
    "\n",
    "feature_columns = ['LotArea', 'YearBuilt', '1stFlrSF', '2ndFlrSF', 'FullBath', 'BedroomAbvGr', 'TotRmsAbvGrd']\n",
    "X = home_data[feature_columns]\n",
    "\n",
    "# 1/4 define\n",
    "iowa_model = DecisionTreeRegressor()\n",
    "# 2/4 fit\n",
    "iowa_model.fit(X, y)\n",
    "# 3/4 predict\n",
    "print(\"First in-sample predictions:\", iowa_model.predict(X.head()))\n",
    "print(\"Actual target values for those homes:\", y.head().tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Split Your Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_X, val_X, train_y, val_y = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Specify and Fit the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(random_state=1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# 1/4 define\n",
    "iowa_model = DecisionTreeRegressor(random_state=1)\n",
    "# 2/4 fit\n",
    "iowa_model.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Make Predictions with Validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3/4 predict\n",
    "val_predictions = iowa_model.predict(val_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect your predictions and actual values from validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[186500. 184000. 130000.  92000.]\n",
      "258    231500\n",
      "267    179500\n",
      "288    122000\n",
      "649     84500\n",
      "Name: SalePrice, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# print the top few validation predictions\n",
    "print(val_predictions[0:4])\n",
    "# print the top few actual prices from validation data\n",
    "print(val_y[0:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you notice that is different from what you saw with in-sample predictions (which are printed after the top code cell in Excercises of this page).\n",
    "\n",
    "*The new predictions are not as accurate as the in-sample predictions.*\n",
    "\n",
    "Do you remember why validation predictions differ from in-sample (or training) predictions? This is an important idea from the last lesson.\n",
    "\n",
    "*The model was built using in-sample predictions which is why the they fit the model perfectly. On the other hand, the model never considered the validation data.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Calculate the Mean Absolute Error in Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29652.931506849316"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4/4 validate\n",
    "val_mae = mean_absolute_error(val_predictions, val_y)\n",
    "val_mae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
